{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d088857e",
   "metadata": {},
   "source": [
    "## Классификация полярности твитов "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc174c9",
   "metadata": {},
   "source": [
    "Датасет: http://help.sentiment140.com/for-students/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08bf0690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9860224b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv', encoding='ansi')\n",
    "\n",
    "df = df.drop(columns=['id', 'date', 'query', 'user'])\n",
    "df.polarity = df.polarity.replace(4,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f5c16f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity                                               text\n",
       "0         0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1         0  is upset that he can't update his Facebook by ...\n",
       "2         0  @Kenichan I dived many times for the ball. Man...\n",
       "3         0    my whole body feels itchy and like its on fire \n",
       "4         0  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7479709b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e296eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.text = dataset.text.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f00b596",
   "metadata": {},
   "source": [
    "Уберем из твитов упоминания (которые начинаются на '@')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "611f417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_mentions(data):\n",
    "    return re.sub('@\\w+',' ',data)\n",
    "dataset.text = dataset.text.apply(clean_mentions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31c4ce2",
   "metadata": {},
   "source": [
    "Уберем ссылки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2eb907e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_URLs(data):\n",
    "    return re.sub('((www.[^\\s]+)|(https?://[^\\s]+))',' ',data)\n",
    "\n",
    "dataset.text = dataset.text.apply(clean_URLs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90aaec0",
   "metadata": {},
   "source": [
    "Уберем знаки препинания:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "340dae73",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "def clean_punctuations(data):\n",
    "    translator = str.maketrans('', '', punctuations)\n",
    "    return data.translate(translator)\n",
    "\n",
    "dataset.text = dataset.text.apply(clean_punctuations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb9d5fc",
   "metadata": {},
   "source": [
    "Уберем цифры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1486d2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_numbers(data):\n",
    "    return re.sub('[0-9]+', '', data)\n",
    "dataset.text = dataset.text.apply(clean_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d227c8",
   "metadata": {},
   "source": [
    "Токенизируем, применим стемминг:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a516d113",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "dataset.text = dataset.text.apply(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0cbdc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.PorterStemmer()\n",
    "def stem(data):\n",
    "    return [stemmer.stem(word) for word in data]\n",
    "\n",
    "dataset.text = dataset.text.apply(stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3a128a",
   "metadata": {},
   "source": [
    "Склеим токены обратно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f56f2574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_back(data):\n",
    "    return ' '. join(data)\n",
    "\n",
    "dataset.text = dataset.text.apply(join_back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227a4b34",
   "metadata": {},
   "source": [
    "Извлечем обучающую и тестовую выборку:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "777e8089",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.text\n",
    "y = dataset.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "293d9024",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3909bee1",
   "metadata": {},
   "source": [
    "Извлечем признаки с помощью count bag of n-grams с последующим tf-idf преобразованием. \n",
    "\n",
    "Все это делается с помощью TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c9f4053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_features=500000, ngram_range=(1, 2))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectoriser = TfidfVectorizer(ngram_range=(1,2), max_features=500000)\n",
    "vectoriser.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "136c7131",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectoriser.transform(X_train)\n",
    "X_test  = vectoriser.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012ecef0",
   "metadata": {},
   "source": [
    "Обучим наивный байесовский классификатор:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78a85019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_bayes = BernoulliNB()\n",
    "naive_bayes.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e00d70",
   "metadata": {},
   "source": [
    "Результат на тестовой выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e533e351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.79     79969\n",
      "           1       0.79      0.81      0.80     80031\n",
      "\n",
      "    accuracy                           0.80    160000\n",
      "   macro avg       0.80      0.80      0.80    160000\n",
      "weighted avg       0.80      0.80      0.80    160000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = naive_bayes.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8aa08a",
   "metadata": {},
   "source": [
    "Обучим классификатор на основе логистической регрессии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "818534dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression = LogisticRegression(max_iter = 1000)\n",
    "linear_regression.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b16db0",
   "metadata": {},
   "source": [
    "Результат на тестовой выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1326d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82     79969\n",
      "           1       0.82      0.83      0.82     80031\n",
      "\n",
      "    accuracy                           0.82    160000\n",
      "   macro avg       0.82      0.82      0.82    160000\n",
      "weighted avg       0.82      0.82      0.82    160000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = linear_regression.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
